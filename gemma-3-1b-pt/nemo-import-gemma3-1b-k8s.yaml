# JobSet is a Kubernetes API for managing a group of jobs as a single unit.
# This manifest defines a JobSet to run a distributed deep learning job.
apiVersion: jobset.x-k8s.io/v1alpha2
kind: JobSet
metadata:
  name: nemo-gpu-import-job
  namespace: default
spec:
  # The number of replicated jobs to create. For a simple job, this can be 1.
  # For distributed training (e.g., with MPI), you would set this to the desired number of replicas.
  replicatedJobs:
    - name: worker
      replicas: 1
      template:
        spec:
          backoffLimit: 0
          template:
            metadata:
              annotations:
                gke-gcsfuse/volumes: "true"
            spec:

              # The imagePullSecrets field has been added to use the ngc-secret.
              imagePullSecrets:
                - name: ngc-secret

              restartPolicy: Never
              containers:
                - name: nemo-container
                  image: nvcr.io/nvidia/nemo:25.09 #nvcr.io/nvidia/nemo:25.07.02
                  env:

                    - name: HF_TOKEN
                      value: "<your-token>"
                    - name: NCCL_DEBUG
                      value: "INFO"
                    - name: HUGGING_FACE_HUB_TOKEN
                      value: "<your-token>"
                    - name: MASTER_ADDR
                      value: "nemo-gpu-import-job-worker-0-0.nemo-gpu-import-job.default.svc.cluster.local"
                    - name: MASTER_PORT
                      value: "3389"
                    - name: MAX_STEPS
                      value: "50"
                    - name: NNODES
                      value: "1"
                    - name: WORLD_SIZE
                      value: "1"
                    - name: GPUS_PER_NODE
                      value: "1"
                    - name: NEMO_MODELS_CACHE
                      value: "/data/nvidia-pipeline/nemo-models/"
                    - name: EXPERIMENT_NAME
                      value: "nemo-finetune-squad"
                    - name: CUDA_DEVICE_MAX_CONNECTIONS
                      value: "1"
                    - name: GLOO_SOCKET_IFNAME
                      value: "eth0"

                  resources:
                    limits:
                      # This limit requests exactly 4 NVIDIA GPUs for the container.
                      nvidia.com/gpu: "1"

                    requests:
                      # It's good practice to set requests equal to limits for GPUs.
                      nvidia.com/gpu: "1"

                  # This volumeMounts section has been added to mount the PVC.
                  volumeMounts:

                    - name: gcs-fuse-csi-ephemeral
                      mountPath: /data

                    - name: dshm
                      mountPath: /dev/shm
                  #command: ["/bin/bash", "-c", "tail -f /dev/null"]

                  command: ["/bin/sh", "-c"]
                  args:
                    - |
                        nemo llm import model=gemma3_1b source="hf://google/gemma-3-1b-pt" -y 
                      
              # This volumes section has been added to link the PVC to the Pod.
              volumes:

                - name: gcs-fuse-csi-ephemeral
                  csi:
                    driver: gcsfuse.csi.storage.gke.io
                    readOnly: false
                    volumeAttributes:
                      bucketName: pmotgi-g4-gemma #pmotgi-g4-checkpoints
                      mountOptions: "implicit-dirs" # Create implicit directories locally when accessed
                - name: dshm
                  emptyDir:
                    medium: Memory
                    sizeLimit: "128Gi"


#Note: If you face OOM on GCP VMs then it could be potential due to boot disk out of memory.
# To update an existing node pool (requires recreating nodes)
#gcloud container node-pools update <node-pool-name> \
#   --cluster=<cluster-name> \
#   --disk-size=500GB \
#   --zone=us-central1-b
